{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reads xml-data\n",
    "def read_data(file):\n",
    "    with open(file, 'r') as f:\n",
    "        data = f.read()\n",
    "    bs_data = bs(data, 'xml') \n",
    "    return bs_data\n",
    "\n",
    "\n",
    "# gets the bname for calculations\n",
    "def get_bname(path):\n",
    "    for xml_file in os.listdir(path):\n",
    "        if xml_file.startswith(\"timeseries\"):\n",
    "            bs_data = read_data(path + xml_file)\n",
    "            b_name = bs_data.find_all('name')\n",
    "            return b_name    \n",
    "\n",
    "# returns a dataframe given some data\n",
    "def values_df(bs_data, low, high):\n",
    "    b_name = bs_data.find_all('name')\n",
    "    attributes = []\n",
    "    # finds all values \n",
    "    for i in range(len(b_name)):\n",
    "        attributes.append(b_name[i].get('value'))\n",
    "\n",
    "    attributes = list(attributes)\n",
    "    collection = {}\n",
    "    \n",
    "    # finds x-, y- and z-values and computes euclidian distance\n",
    "    for i in range(low, high):\n",
    "        r = calc(b_name, i)\n",
    "        collection[attributes[i]] = r\n",
    "\n",
    "    df = pd.DataFrame(collection)\n",
    "    return df\n",
    "\n",
    "def get_differences_values(path):\n",
    "    i = 0\n",
    "    ts_dict = {}\n",
    "    \n",
    "    for xml_file in os.listdir(path):\n",
    "        if xml_file.startswith(\"timeseries\"):\n",
    "            try:\n",
    "                bs_data = read_data(path + xml_file)\n",
    "                b_name = bs_data.find_all('name')\n",
    "                \n",
    "                pl = [(0, int(len(b_name)/4)),\n",
    "                       (int(len(b_name)/4), int(len(b_name)/2)),\n",
    "                       (int(len(b_name)/2), int(3*len(b_name)/4)),\n",
    "                       (int(3*len(b_name)/4), len(b_name))]\n",
    "            \n",
    "                pl_list = [] # power level list\n",
    "                for low, high in pl:\n",
    "                    \n",
    "                    df = values_df(bs_data, low, high)\n",
    "\n",
    "                    df_max = pd.DataFrame(df.max().to_dict(),index=[df.index.values[-1]])\n",
    "                    df_min = pd.DataFrame(df.min().to_dict(),index=[df.index.values[-1]])\n",
    "                    df = df_max.subtract(df_min, fill_value=0)\n",
    "                    \n",
    "                    pl_list.append(df)\n",
    "                \n",
    "                if \"healthy\" in path.lower():\n",
    "                    injurylevel = [0 for i in range(len(pl_list))]\n",
    "                else: \n",
    "                    injurylevel = [1 for i in range(len(pl_list))]\n",
    "                \n",
    "                df = pd.concat(pl_list)\n",
    "                df = df.reset_index(drop=True)\n",
    "                df.drop([\"Left Foot Progression\", \"Right Foot Progression\"], axis = 1, inplace = True)\n",
    "                df['Injury level'] = injurylevel\n",
    "                \n",
    "                ts_dict[xml_file] = df\n",
    "            except:\n",
    "                print(xml_file + \" failed to compute\")\n",
    "    return ts_dict\n",
    "\n",
    "# calculates the euclidian values\n",
    "def calc(b_name, i):\n",
    "    a1 = b_name[i].find_all('component')[0].get('data')\n",
    "    b1 = b_name[i].find_all('component')[1].get('data')\n",
    "    c1 = b_name[i].find_all('component')[2].get('data')\n",
    "    x = np.asarray([float(x) for x in a1.split(',')])\n",
    "    y = np.asarray([float(y) for y in b1.split(',')])\n",
    "    z = np.asarray([float(z) for z in c1.split(',')])\n",
    "    r = (x**2 + y**2 + z**2)**0.5\n",
    "    return r\n",
    "\n",
    "def ts_df(path):\n",
    "    ts_list = []\n",
    "    \n",
    "    for xml_file in os.listdir(path):\n",
    "        if xml_file.startswith(\"timeseries\"):\n",
    "            ts_list.append(xml_file)\n",
    "        \n",
    "    #df = pd.DataFrame({'timeseries': ts_list})\n",
    "    return ts_list\n",
    "\n",
    "def cross_validation(ts_list, n_folds, p): \n",
    "    test = []\n",
    "    train = []\n",
    "    \n",
    "    for n in range(n_folds):\n",
    "        random.shuffle(ts_list)\n",
    "        \n",
    "        test.append(ts_list[:int(p*len(ts_list))])\n",
    "        train.append(ts_list[int(p*len(ts_list)):])\n",
    "    \n",
    "    data = {'test': test, 'train': train}\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"usethis/Healthy/\"\n",
    "healthy_dict = get_differences_values(path)\n",
    "\n",
    "path = \"usethis/PFPS/\"\n",
    "pfps_dict = get_differences_values(path)\n",
    "\n",
    "ts_dict = {**healthy_dict, **pfps_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"usethis/Healthy/\"\n",
    "healthy = ts_df(path)\n",
    "\n",
    "path = \"usethis/PFPS/\"\n",
    "pfps = ts_df(path)\n",
    "\n",
    "cv_healthy = cross_validation(healthy, 10, 0.2)\n",
    "cv_pfps = cross_validation(pfps, 10, 0.2)\n",
    "\n",
    "cv = cv_healthy + cv_pfps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data from different fold list\n",
    "def extract_data(flod_list):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for fold in flod_list:\n",
    "        temp_list = []\n",
    "        random.shuffle(fold)\n",
    "        \n",
    "        for ts in fold:\n",
    "            temp_list.append(ts_dict.get(ts))\n",
    "            \n",
    "        df = pd.concat(temp_list)\n",
    "        df = df.reset_index(drop=True)\n",
    "        \n",
    "        y_df = df['Injury level']\n",
    "        x_df = df.drop(['Injury level'], axis = 1)\n",
    "        \n",
    "        X.append(x_df)\n",
    "        y.append(y_df)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "def get_X_data(X_test, X_train):\n",
    "    my_imputer = SimpleImputer()\n",
    "    imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n",
    "    imputed_X_test = pd.DataFrame(my_imputer.transform(X_test))\n",
    "\n",
    "    imputed_X_train.columns = X_train.columns\n",
    "    imputed_X_test.columns = X_test.columns\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(imputed_X_train)\n",
    "    X_test = sc.transform(imputed_X_test)\n",
    "    \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = extract_data(cv['train'])\n",
    "X_test, y_test = extract_data(cv['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB - Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb(X_test, X_train, y_train, y_test):\n",
    "    XGB_classifier = XGBClassifier(use_label_encoder = False,\n",
    "                              learning_rate=0.1,\n",
    "                              max_depth=10,\n",
    "                              scale_pos_weight=1.5,\n",
    "                              eval_metric='mlogloss')\n",
    "    XGB_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # MAKE PREDICTION\n",
    "    y_pred = XGB_classifier.predict(X_test)\n",
    "    score1 = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[-0.67750388 -0.92613942 -0.68649574 -0.08477118  0.82530647  0.49439046\n  0.27766573 -1.01244394 -0.61653997 -0.60176469 -0.4413632  -0.39256992\n -0.81347757 -0.16129862 -0.68168498  0.1504516  -0.71881462 -0.50639832\n  0.04020297  0.18816557  0.04995187  0.43001897 -0.99609169 -0.57853215\n -0.55560577 -0.78333001 -0.19562115 -0.78687442 -0.38995342 -0.38395706].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/n7/zkztf1z93sb1wpcbr3wrk07c0000gn/T/ipykernel_91244/1034043965.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_X_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0maccuracy_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/n7/zkztf1z93sb1wpcbr3wrk07c0000gn/T/ipykernel_91244/3032375347.py\u001b[0m in \u001b[0;36mget_X_data\u001b[0;34m(X_test, X_train)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_X_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mmy_imputer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleImputer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mimputed_X_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_imputer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mimputed_X_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_imputer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/BikeFit/venv/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/BikeFit/venv/lib/python3.7/site-packages/sklearn/impute/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \"\"\"\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_fit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;31m# default fill_value is 0 for numerical input and \"missing_value\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/BikeFit/venv/lib/python3.7/site-packages/sklearn/impute/_base.py\u001b[0m in \u001b[0;36m_validate_input\u001b[0;34m(self, X, in_fit)\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mnew_ve\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0m_check_inputs_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissing_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/BikeFit/venv/lib/python3.7/site-packages/sklearn/impute/_base.py\u001b[0m in \u001b[0;36m_validate_input\u001b[0;34m(self, X, in_fit)\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m                 \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m                 \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m             )\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mve\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/BikeFit/venv/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/BikeFit/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    771\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m                     \u001b[0;34m\"if it contains a single sample.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m                 )\n\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[-0.67750388 -0.92613942 -0.68649574 -0.08477118  0.82530647  0.49439046\n  0.27766573 -1.01244394 -0.61653997 -0.60176469 -0.4413632  -0.39256992\n -0.81347757 -0.16129862 -0.68168498  0.1504516  -0.71881462 -0.50639832\n  0.04020297  0.18816557  0.04995187  0.43001897 -0.99609169 -0.57853215\n -0.55560577 -0.78333001 -0.19562115 -0.78687442 -0.38995342 -0.38395706].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "accuracy_list = []\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    X_train, X_test = get_X_data(X_test[i], X_train[i])\n",
    "    \n",
    "    accuracy = xgb(X_test, X_train, y_train[i].values, y_test[i].values)\n",
    "    accuracy_list.append(accuracy)\n",
    "    \n",
    "accuracy_mean = np.mean(accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.49171099,  0.22505398,  0.41441444, ...,  0.29232891,\n",
       "        -0.82591562, -0.78678933],\n",
       "       [-0.55694243,  0.53202485,  0.15580859, ...,  0.35642254,\n",
       "        -0.55564176, -0.70285866],\n",
       "       [-0.39908419,  0.70132586,  0.04082704, ...,  0.3450834 ,\n",
       "        -0.46670051, -0.61615745],\n",
       "       ...,\n",
       "       [-0.25802897, -0.31413996,  0.74694779, ..., -0.88164959,\n",
       "        -0.2412709 , -0.5791932 ],\n",
       "       [-0.02384506, -0.45223795,  0.80840482, ..., -1.24988511,\n",
       "         0.        , -0.46158864],\n",
       "       [ 2.17098483, -1.67295153,  0.96391595, ..., -1.32226763,\n",
       "        -0.30000391,  0.67940839]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(accuracy_mean)\n",
    "display(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
